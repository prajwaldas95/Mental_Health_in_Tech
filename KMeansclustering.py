# -*- coding: utf-8 -*-
"""DM Project Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19K02IGXCK5elQRP1wqwjuivuh8chvQSq
"""

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import stats
from sklearn import preprocessing
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from matplotlib.patches import Rectangle
from google.colab import drive
from google.colab import drive
#drive.mount('/content/gdrive')

#data = pd.read_csv("gdrive/My Drive/Colab Notebooks/data/raw/osmi-survey-data.csv")
data=pd.read_csv("mental-heath-in-tech-2016_20161114.csv")
intFeatures = ['What is your age?',
              'Is your primary role within your company related to tech/IT?',
              'Do you have previous employers?',
              'Have you ever sought treatment for a mental health issue from a mental health professional?']

data.head()


data=data.fillna(0)
print(data)
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler



# kmeans = KMeans(init="random",n_clusters=3,n_init=10,max_iter=300,random_state=42)

# kmeans.fit(data)
# kmeans.cluster_centers_

# print(np.unique(kmeans.labels_))
from sklearn import preprocessing
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler


labelDict = {}
for features in data:
	le = preprocessing.LabelEncoder()
  #print("a")
 

  
  
  # le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
  # data[feature] = le.transform(data[feature])
  #   # Get labels
  # labelKey = 'label_' + feature
  # labelValue = [*le_name_mapping]
  # labelDict[labelKey] =labelValue
    
# for key, value in labelDict.items():     
#     print(key, value)



# for x in range(len(data)):
# 	print(data.iloc[x][0])

labelDict = {}
# for features in data:
# 	le = preprocessing.LabelEncoder()
#   print("a")
#   e.fit(train_df[feature])




le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    train_df[feature] = le.transform(train_df[feature])
    # Get labels
    labelKey = 'label_' + feature
    labelValue = [*le_name_mapping]
    labelDict[labelKey] =labelValue



#Encoding data
labelDict = {}
for feature in train_df:
    le = preprocessing.LabelEncoder()
    le.fit(train_df[feature])
    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    train_df[feature] = le.transform(train_df[feature])
    # Get labels
    labelKey = 'label_' + feature
    labelValue = [*le_name_mapping]
    labelDict[labelKey] =labelValue

from yellowbrick.cluster import KElbowVisualizer
from google.colab import drive
drive.mount('/content/gdrive')
plt.figure(figsize=(30,20))

data = pd.read_csv("gdrive/My Drive/Colab Notebooks/data/raw/osmi-survey-2016_data.csv")
#data = pd.read_csv("osmi-survey-2016_data.csv")
data.head()
feat=data.columns
#print(len(feat))
data=data.fillna(0)
#print(data)
labelDict={}
for features in data:
  le=preprocessing.LabelEncoder()
  le.fit(list(data[features]))
  le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
  data[features] = le.transform(list(data[features]))
  labelKey = 'label_' + features
  labelValue = [*le_name_mapping]
  # print(labelKey,labelValue)

  labelDict[labelKey] =labelValue


# print(data)
Kmeanmodel = KMeans(random_state=0)
plt.figure(figsize=(7,3.5))
viz= KElbowVisualizer(Kmeanmodel, k=(2,11),timings=False)
viz.fit(data)
____=viz.show()

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from scipy import stats
from sklearn import preprocessing
from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
import seaborn as sns
from matplotlib.patches import Rectangle
from google.colab import drive
#drive.mount('/content/gdrive')
plt.figure(figsize=(30,20))
# mental-heath-in-tech-2016_20161114
#data = pd.read_csv("gdrive/My Drive/Colab Notebooks/data/raw/osmi-survey-2016_data.csv")
data=pd.read_csv("mental-heath-in-tech-2016_20161114.csv")
data.head()
feat=data.columns
#print(len(feat))
data=data.fillna(0)
#print(data)
labelDict={}
for features in data:
  le=preprocessing.LabelEncoder()
  le.fit(list(data[features]))
  le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
  data[features] = le.transform(list(data[features]))
  labelKey = 'label_' + features
  labelValue = [*le_name_mapping]
  # print(labelKey,labelValue)

  labelDict[labelKey] =labelValue

#sns.set()
# print(data)

n_clusters=4 

kmeans = KMeans(init="random",n_clusters=n_clusters,n_init=10,max_iter=300,random_state=42)


kmeans.fit(data)
print(kmeans.labels_)
# print(kmeans.cluster_centers_)


# print(len(labelDict))
# print((labelDict))
def show_dist(feature, num):
  labelKey = 'label_' + feat[feature]
  print("****",labelKey)
  temp_dict={}
  for j in labelDict[labelKey]:
    # if (len(labelDict[labelKey])>2) and j=='0':
    #   continue
    temp_dict[j]=[0]* num


  lis=[0]*num
  
  print(":***",len(data.index))
  for i in range(len(data.index)):
    if labelDict[labelKey][data.iloc[i][feature]] in temp_dict:
     #temp_dict[labelDict[labelKey][data.iloc[i][feature]]][data.iloc[i][-1]]+=1
     temp_dict[labelDict[labelKey][data.iloc[i][feature]]][kmeans.labels_[i]]+=1
  print("!!!!!!",temp_dict)
  for i in temp_dict:
    # if len(temp_dict)>2 and i=='0':
    #   continue
    for j in range(len(temp_dict[i])):
      print(i)
      # temp_dict[labelDict[labelKey][data.iloc[i][feature]]][data.iloc[i][-1]]
      lis[j]+= temp_dict[i][j]

  print(lis)
  for i in temp_dict:
    for j in range(len(temp_dict[i])):
      temp_dict[i][j]= temp_dict[i][j]/lis[j] *100
  print(temp_dict)
  fig, ax = plt.subplots()
  class_label=[]
  for i in range(num):
    class_label.append("Class "+str(i+1))
  answers=temp_dict.keys()
  colors = ['lightsteelblue','yellowgreen','thistle','pink','bisque']
  prev=[]
  c=0
  j=0
  for i in temp_dict:
    print(len(temp_dict))
    t=np.array(temp_dict[i])
    if c==0:
      ax.bar(class_label,t, color=colors[c],label=i,width=0.4,alpha=0.3)
      prev=t
    else:
      ax.bar(class_label,t, color=colors[c],bottom=prev, label=i,width=0.4,alpha=0.3)
      prev+=t
    c+=1    
  ax = plt.gca()
  for p in ax.get_children()[:-1]:  # skip the last patch as it is the background
    if isinstance(p, Rectangle):
        x, y = p.get_xy()
        w, h = p.get_width(), p.get_height()
        if h > 4:  # anything that have a height of 0 will not be annotated
            ax.text(x + 0.5 * w, y + 0.5 * h, '%0.2f'%h+"%", va='center', ha='center')

  plt.gcf().set_size_inches(7, 3.5)

  ax.set_yticks([0,10,20,30,40,50,60,70,80,90,100])
  ax.set_xlabel('Perspective for: '+feat[feature])
  ax.set_ylabel('Percentage')
  ax.set_title('Perspective Analysis')
  ax.set_xticks(np.arange(0, 4, 1))
  ax.set_yticks(np.arange(0, 100, 10))

  plt.grid(linestyle='--', alpha = 0.8)
  plt.tight_layout()
  ax.legend(bbox_to_anchor=(1, 1),facecolor='white', framealpha=1,frameon=True)
  plt.savefig("../media/health_benifit.png")
  plt.show()


show_dist(2,n_clusters)

for i in range(len(feat)):
  print(i,feat[i])


print(data.info)





















































